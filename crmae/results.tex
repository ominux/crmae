In this section, we provide a comparative analysis of the performance and energy results of the six designs.
We also discuss the sensitivity of of several architectural parameters.
%experimental results associated with our design choices.



\begin{figure*} [t]
%\begin{figure*} [t]
\centering
 \psfig{figure=figures/parsec-speedup.eps, width=6.9in, height=2.5in}
 \hrule
 \caption{\label{fig:parsec-new} \scriptsize \bf Normalized speedup for PARSEC Applications }
%\end{figure*}
\end{figure*}



\subsection {Performance comparison}
Figure \ref{fig:parsec-new} shows speedup improvements of a subset of PARSEC
multithreaded applications along with the average (taken across 12 PARSEC applications listed in Table~\ref{}).
All speedup numbers are normalized to S-1MB.
For the M-4MB design, the applications to the right of x264 (including x264) exhibit
speedup improvements over S-1MB because these are read intensive applications as shown in Table 3.
The read intensive applications not only benefit from the 4x capacity increase of STT-RAM, but also
because of the presence of a write buffer for the L2 cache.
To see the benefits of write buffer,  let us consider fluidanimate and vips applications.
Even though they have high number of writes to the L2 cache, the writes are staggered, which help the write buffer in ameliorating increased write latency.
The applications to the left of x264 are write intensive applications and thus, we see degradation in speedup
because of the STT-RAM high write latency.
On an average, traditional 10 year STT-RAM gives 3\% speedup improvement over S-1MB because most of the read
intensive applications show considerable improvement in speedup (maximum speedup observed was YY\% for application
XX).



\begin{figure*} [t]
%\begin{figure*} [t]
\centering
 \psfig{figure=figures/spec-ws.eps, width=3.9in, height=2.5in}
 \hrule
 \caption{\label{fig:spec-new} \scriptsize \bf Normalized Average Instruction Throughput(IT) and Weighted Speedup(WS) for SPEC 2006 multiprogrammed mixes. }
%\end{figure*}
\end{figure*}


Next, let us consider Volatile M-4MB(1sec) design. This design has no refreshing scheme, but since within 1 sec interval,
almost all the blocks are refreshed inherently as per application characteristics discussed in Section ~\ref{},
we observe speedup improvements of this design over M-4MB in all the applications because of the reduced
write latency (12 cycles compared to 22 cycles).
Again for a few of the write intensive application like swaptions, M-4MB(1sec) has no speedup gain compared to
the base case S-1MB SRAM cache design.
Volatile M-4MB(10ms) design also does not have any refreshing scheme, but the retention time of STT-RAM
cells used is 10ms, which triggers large number of write backs.
Figure~\ref{fig:writebacks} shows number of write backs of all the designs normalized to M-4MB.
We observe that this design, on an average, has 21\% more
write backs than the traditional STT-RAM design.
For this reason, in vips, there is about 20\% speedup degradation over M-4MB.
It is interesting to see the case of swaptions, where there is a slight improvement in speedup over M-4MB, although
there is increase in number of write backs. The reason for this improvement is due to the fact that
the majority of blocks that are not refreshed within 10ms interval,
are not accessed in future as well leading to a low number of read misses.
This helps in reaping benefits from the reduced write latency.

Our scheme revived-M-4MB(10ms), which incorporates refreshing of dirty blocks beyond the 10ms retention time,
depicts speedup improvements
in almost all applications except for fluid, in which all the dirty blocks are almost equally distributed among
all the ways. Hence, our scheme of the considering only first eight MRU slots does not prevent in stopping
many writebacks. This observation can also be made from Figure~\ref{fig:writebacks}, where write backs in our scheme are also
very high. On an average,  the proposed revived scheme is better than the conventional SRAM design (S-1MB) by 18\%,
traditional 10yr STT-RAM by 15\% and over Volatile STT-RAM (1sec)
by 4.5\% (In case of facesim, our scheme is better than Volatile STT-RAM (1 sec) by 22.7\%).
The revived-M-4MB(10ms) scheme is closest to the ideal S-4M case with difference of only 4\%.

Figure~\ref{fig:spec-new} shows instruction throughput and weighted speedup for the  SPEC multiprogram
mixes. We observe that our scheme revived-M-4MB gives 22\% improvement in instruction throughput
over M-4MB, 11\% improvement over Volatile STT-RAM (1 sec), and 10\% improvement over
the base line SRAM cache. (although not shown in the Figure due to brevity, in case of the mix of
bzip2, gcc, lbm, hmmer, the improvement is 15\%). The weighted speedup improvement over M-4MB is 4\%
and over Volatile STT-RAM(1 sec) is 2\%. (NEED TO EXPLIAN WHY annd more insight).


\subsection {Energy comparison}
Figure~\ref{fig:energy} shows normalized leakage, total of dynamic read and write energy, and total energy.
The number of reads and writes to L2 cache are only considered for the calculation of dynamic energy.
We observe that on an average there is 44\% improvement in total energy going from S-1MB to
M-4MB designs. The improvement is mainly because of the drastic reduction in leakage energy.
Volatile M-4MB(1sec) leakage benefits over M-4MB correlates with the performance improvement.
On an average, this design consume more dynamic energy than M-4MB. The dynamic energy fluctuations among
different applications are on account of changes in number of read and writes. Additional write backs
triggers read misses which ultimately lead to additional writes to L2 cache. Write energies of 1sec design is more
than the 10ms designs, which makes the fluctuations depend on the number of reads/writes.

We see 11\% energy benefits of using revived M-4MB design over Volatile-1sec and 30\% improvement over
M-4MB designs.The energy numbers of this scheme covers all the overheads of  the buffer design.
We observe that our scheme is better in terms of both performance and energy over Volatile-4MB(1sec) and
M-4MB designs.

\begin{figure*} [t]
\centering
\begin{tabular}{c}
\psfig{figure=figures/legend.eps, width=5.5in, height=0.15in}
\end{tabular}
\begin{tabular}{ccc}
 \psfig{figure=figures/leak-eng.eps, width=2.1in, height=2.0in} &
\psfig{figure=figures/dyn-eng.eps, width=2.1in, height=2.0in} &
\psfig{figure=figures/tot-eng.eps, width=2.1in, height=2.0in} \\
\scriptsize (a) Leakage Energy  & \scriptsize (b) Dynamic Energy & \scriptsize (c) Total Energy
\end{tabular}
 \hrule
 \caption{\scriptsize \bf Energy of Applications Normalized to that of S-1MB}
\label{fig:energy}
\end{figure*}


\begin{figure*} [t]
%\begin{figure*} [t]
\centering
 \psfig{figure=figures/writebacks.eps, width=4.9in, height=2.5in}
 \hrule
 \caption{\label{fig:writebacks} \scriptsize \bf Number of Write backs normalized to M-4MB}
%\end{figure*}
\end{figure*}





\subsection{Sensitivity Analysis}

\noindent\textbf{Sensitivity to number of Buffer entries:}
For this analysis, we calculate 95\% confidence intervals for the cummulative distribution of 
dead blocks per bank as shown in~\ref{fig:confi}. We observe that, for first 8 MRU slots, 
mean value of the buffer entries is 1900 blocks. Upper limit corresponding to 8 MRU slots
is 2500 blocks.
Figure~\ref{fig:buf-mru} shows speedup of PARSEC applications by varying buffer number
of buffer enteries. Going from 1900 to 2500 (3\% to 4\% overhead over L2 cache bank) is giving
only less than 0.5\% speedup improvement. Hence we took 1900 as buffer size to minimize the
overhead. 

\begin{figure*} [t]
\centering
\begin{tabular}{cc}
 \psfig{figure=figures/buffer.eps, width=3.4in, height=2.0in} &
\psfig{figure=figures/slots.eps, width=3.4in, height=2.0in} \\
\scriptsize (a) Buffer Slots & \scriptsize (b) MRU Slots
\end{tabular}
 \hrule
 \caption{\scriptsize \bf Showing effects on speedup by varying number of Buffer and MRU Slots }
\label{fig:buf-mru}
\end{figure*}


\noindent\textbf{Sensitivity to number of MRU slots:}
We observe from figure~\ref{fig:buf-mru} that decreasing MRU slots hampers the performance
as  many frequently read blocks are not refreshed. Increasing MRU slots, will make the
buffer overflow. 



\begin{figure*} [t]
%\begin{figure*} [t]
\centering
 \psfig{figure=figures/confi.eps, width=3.9in, height=2.5in}
 \hrule
 \caption{\label{fig:confi} \scriptsize \bf 95\% Confidence Intervals of Diminished Blocks for each Way}
%\end{figure*}
\end{figure*}



\noindent\textbf {Sensitivity to number of bits of the counter}
There is no observable difference in performance and energy by increase in the number of bits of the counter.








