%[ADWAIT, MORE STT-RAM RELATED WORK other than HPCA 2011 paper ESPECIALLY FOR STT-RAM CACHE DESIGN should be put here]

%Liang et al.~\cite{3t1d-cache} studied the impact of process variation on a 3T1D
%L1 data cache and modeled the process variations as variations in data retention time.

%Below, we discuss the prior works most relevant to our work.

%This section summarizes the prior work closely related to ours.
This section summarizes the circuit and architectural techniques proposed for enhancing the STT-RAM
write performance.

The work that is most closely related to ours is~\cite{STTRAM:HPCA11}.
Here, the authors relax the retention time of STT-RAM from $10 years$ to $56 \mu s$ by
reducing the planar area of MTJ from $32F^2$ to $10F^2$. The scope of their work is limited by
addressing reasonable device parameters and their variabilities. Recently published work related to 
STT-RAM~\cite{PMTJ:Toshiba08,STTRAM:EDL11,STTRAM:Qualcomm09,STTRAM:Grandis11} 
uses state-of-the-art MTJ designs in the range of 2-3$F^2$. Since, these designs don't give the
leeway of reducing the retention time by aggressively reducing the MTJ planar area, we reduce the
retention time by focusing on the material property and the thickness of the MTJ. 
Analysis of
retention times of LLC blocks with 25 multi-threaded and multi-programmed applications, 
as compared to only 5 applications in~\cite{STTRAM:HPCA11}, shows that 
the ideal retention time of LLC should be in the order of $ms$, which also makes
the case for our device level modeling. Moreover, {\it $\mu$s} retention time proposed
in their work, may be theoretical possible, 


The 3T1D designs proposed in
~\cite{3T-brooks} has typical worst-case retention time in {\it $\mu$s} region,
which makes it unsuitable for our LLC design. Also, our proposed refresh scheme is simple, yet 
very performance and energy efficient compared to the DRAM-style refreshing 
proposed in~\cite{STTRAM:HPCA11}. 

We recently came across the work which explores the possibility of designing LLC with STT-RAM banks of varying 
retention times and moving dying blocks from lowest retention time ({\it $\mu$s}) bank to the higher ones. First of all fabricating STT-RAM cell with microsecond retention time is extremely challenging and prone to process variations. Moreover, including different types of STT-RAM cells corresponding to different retention times in the same hierarchy will impose greater challenge and incur higher die cost. The energy numbers in their work also seem to be too optimistic and doesn't correlate with our NVsim simulation results.

Apart from this recent work, few other prior works have also proposed architectural and circuit level
solutions to handle this long write latency problem in STT-RAMs. Architectural techniques such as
early write termination~\cite{mram-energy-reduction}, hybrid SRAM/STT-RAM
architecture~\cite{gsun-hpca, Qureshi:2009:SHPMM} and read-preemptive write-buffer designs have been
shown to mitigate write latency/energy. The circuit level techniques such as eliminating redundant
bit-writes~\cite{mram-energy-reduction} and data inverting technique~\cite{gsun-hpca} have also been
shown to be effective in hiding the long write latency. In contrast to all these prior works that
attempt to {\it hide} the write latency, our scheme investigates techniques to {\it actually} reduce
the write latency of STT-RAM banks and make their write latency comparable to SRAM banks. When
compared to Zhou et al.'s work~\cite{mram-energy-reduction} that require additional gates for
detection and termination of writes inside {\it each STT-RAM sub-bank}, our techniques are simpler to
implement since our proposal works at a much coarser granularity.

Sun et al.~\cite{gsun-hpca} showed that write buffers can be helpful in hiding the long write
latencies of STT-RAM banks. Our analysis shows that, if an application is bursty, write-buffers fail
to hide this latency and are rendered in-effective. Out of 25 applications, we found 12 applications
to be write intensive and bursty and hence, write-buffering is ineffective for these applications.
Moreover, all our results are conservative since we have already assumed a 10-entry (as used
in~\cite{gsun-hpca}) write-buffer at every STT-RAM bank and our results would be significantly better
without the presence of write-buffers.

In a recent work~\cite{mram-noc}, the authors have proposed a network level solution to hide the
write latency of STT-RAM banks. This solution requires complex busy/idle bank detection followed by
prioritization mechanisms in the network. On a qualitative basis, the network level solution to hide
write latency in \cite{mram-noc} was shown as the most promising technique compared to any other
techniques. The application level performance improvement with this scheme was about 2-4\% higher
compared to the write buffering technique of Sun et al.~\cite{gsun-hpca}. Contrasting this to our
work here, our scheme provides about 15\%/4\%(PARSEC IPC/SPEC weighted-speedup) improvement over $10year$
traditional STT-RAM, on top of the write buffering scheme, thereby making it more attractive compared
to \cite{mram-noc}. Overall, we believe that no prior work makes a case for tuning the retention time
of STT-RAM banks that is based on profiling retention duration of last-level cache blocks of
applications, which our proposal does.
